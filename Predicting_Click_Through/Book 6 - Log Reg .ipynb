{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book 6 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patheffects as path_effects\n",
    "from matplotlib import cm as cm2\n",
    "matplotlib.style.use('ggplot') \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, \\\n",
    "    GradientBoostingClassifier, ExtraTreesClassifier, BaggingRegressor, \\\n",
    "    ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score \\\n",
    "#     confusion_matrix, roc_curve, roc_auc_score, precision_score, recall_score\n",
    "from sklearn.cross_validation import train_test_split, KFold, cross_val_score\n",
    "\n",
    "\n",
    "matplotlib.style.use('ggplot') \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring in X & T train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('X_train.pkl', 'r') as picklefile:\n",
    "    X_train = pickle.load(picklefile)\n",
    "    \n",
    "with open('X_test.pkl', 'r') as picklefile:\n",
    "    X_test = pickle.load(picklefile)\n",
    "    \n",
    "with open('Y_train.pkl', 'r') as picklefile:\n",
    "    Y_train = pickle.load(picklefile)\n",
    "    \n",
    "with open('Y_test.pkl', 'r') as picklefile:\n",
    "    Y_test = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = np.transpose(Y_test.values)[0]\n",
    "Y_train = np.transpose(Y_train.values)[0]\n",
    "type(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Disp_train.pkl', 'r') as picklefile:\n",
    "    Disp_train = pickle.load(picklefile)\n",
    "    \n",
    "with open('Disp_test.pkl', 'r') as picklefile:\n",
    "    Disp_test = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length: 23,179\n",
      "X_test  length:  2,396\n"
     ]
    }
   ],
   "source": [
    "print('X_train length: {0:,}'.format(len(X_train)))\n",
    "print('X_test  length:  {0:,}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined length: 25,575\n"
     ]
    }
   ],
   "source": [
    "X = X_train.append(X_test)\n",
    "print('Combined length: {0:,}'.format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'pltfrm', u'state', u'cmpgn_id', u'adv_id', u'period', u'doc_topic',\n",
       "       u'ad_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:07.385958\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "X = pd.get_dummies(X, prefix=['pltfrm', 'state', 'cmpgn_id', 'adv_id',\\\n",
    "                                          'period','doc_topic', 'ad_topic'])\n",
    "\n",
    "X.drop(['pltfrm_3','state_AK','cmpgn_id_32840','adv_id_1890','period_morning',\n",
    "       'doc_topic_17.0','ad_topic_91.0'])\n",
    "finish = datetime.datetime.now()\n",
    "print(finish - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X[:23179]\n",
    "X_test = X[23179:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length: 23,179\n",
      "X_test  length:  2,396\n"
     ]
    }
   ],
   "source": [
    "print('X_train length: {0:,}'.format(len(X_train)))\n",
    "print('X_test  length:  {0:,}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regresion\n",
    "\n",
    "Log Reg default settings\n",
    "* correct predictions: 167\n",
    "* Precent correct: 36.5%\n",
    "\n",
    "Log Reg default settings (C=10)\n",
    "* correct predictions: 170\n",
    "* Precent correct: 37.2%\n",
    "\n",
    "Log Reg default settings (C=5 & 12)\n",
    "* correct predictions: 169\n",
    "* Precent correct: 37.0%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=12, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression(C=12)\n",
    "\n",
    "lg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> Post Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get probabilities of clicked/not clicked\n",
    "lg_proba = lg.predict_proba(X_test)\n",
    "lg_Y_proba = pd.DataFrame(lg_proba,columns = ['p_no_click','p_click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ppp = pd.concat([Disp_test, lg_Y_proba], axis=1)\n",
    "# post processing of predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce to 1-click per display id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>p_no_click</th>\n",
       "      <th>p_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65537</td>\n",
       "      <td>0.979695</td>\n",
       "      <td>0.020305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65537</td>\n",
       "      <td>0.964360</td>\n",
       "      <td>0.035640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65537</td>\n",
       "      <td>0.941279</td>\n",
       "      <td>0.058721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_id  p_no_click   p_click\n",
       "0       65537    0.979695  0.020305\n",
       "1       65537    0.964360  0.035640\n",
       "2       65537    0.941279  0.058721"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker = ppp\n",
    "checker.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>p_no_click</th>\n",
       "      <th>p_click</th>\n",
       "      <th>Y_test</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65537</td>\n",
       "      <td>0.979695</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65537</td>\n",
       "      <td>0.964360</td>\n",
       "      <td>0.035640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65537</td>\n",
       "      <td>0.941279</td>\n",
       "      <td>0.058721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65537</td>\n",
       "      <td>0.866812</td>\n",
       "      <td>0.133188</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66286</td>\n",
       "      <td>0.751342</td>\n",
       "      <td>0.248658</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_id  p_no_click   p_click  Y_test  prediction\n",
       "0       65537    0.979695  0.020305       0           0\n",
       "1       65537    0.964360  0.035640       0           0\n",
       "2       65537    0.941279  0.058721       0           0\n",
       "3       65537    0.866812  0.133188       1           0\n",
       "4       66286    0.751342  0.248658       1           0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker['Y_test'] = pd.Series(Y_test)\n",
    "checker['prediction'] = [0 for _ in range(len(checker))] # puts zeros in place\n",
    "checker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of unique display_id's, with each display id corresponding to an event\n",
    "pages = checker['display_id'].unique()\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# system to use probabilities to choose which page is clicked\n",
    "# compensates for zero probability across the board, or muliple matching high probabilities\n",
    "\n",
    "for d_num in pages:  \n",
    "    indx = 0 # index that becomes click\n",
    "    disp_list = checker[checker['display_id'] == d_num].index.tolist()\n",
    "\n",
    "    temp = pd.DataFrame(ppp[ppp['display_id'] == d_num])\n",
    "\n",
    "    p_max = temp['p_click'].max()\n",
    "\n",
    "    if p_max == 0:\n",
    "        indx = random.choice(disp_list) # randomly picks from all matched values\n",
    "    else:\n",
    "        counter = 0\n",
    "        short_list =[]\n",
    "        for index, row in temp.iterrows():\n",
    "            if row['p_click'] == p_max:\n",
    "                counter += 1\n",
    "                short_list.append(index)\n",
    "        indx = random.choice(short_list) # randomly picks from all matched values\n",
    "    checker.set_value(indx, 'prediction', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(checker['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(checker['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicks correctly predicted: 169\n",
      "Percent correctly predicted: 36.980306%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index, row in checker.iterrows():\n",
    "    if row['prediction'] == 1 and row['Y_test'] == 1:\n",
    "        count +=1\n",
    "print('Clicks correctly predicted: {0:,}'.format(count))\n",
    "print('Percent correctly predicted: {0:%}'.format(float(count)/sum(checker['Y_test'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# <font color='purple'> Gridsearch goes below: <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LogisticRegression(C=12, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='precision', verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(lg, scoring = \"precision\",\n",
    "                    param_grid = {'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]})\n",
    "grid.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
